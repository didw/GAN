{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고:\n",
    "http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html\n",
    "http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-2.html\n",
    "https://github.com/wiseodd/generative-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 구조\n",
    "#### a. Generator\n",
    " - Image를 만드는 부분\n",
    " \n",
    "#### b. Discriminator\n",
    "  - 만들어진 image를 평가하는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 예\n",
    "지폐위조범(**Generator**)은 경찰을 최대한 열심히 속이려고하고\n",
    "다른 한편에서는 경찰(**Discriminator**)이 이렇게 위조된 지폐를 진짜와 감별하려고(Classify) 노력한다.\n",
    "이런 경쟁 속에서 두 그룹 모두 속이고 구별하는 서로의 능력이 발전하게 되고 결과적으로는 진짜 지폐와 위조 지폐를 구별할 수 없을 정도(구별할 확률 \\\\(P_d=0.5)\\\\)에 이른다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative model G는 우리가 갖고 있는 data x의 distribution을 알아내려고 노력한다. 만약 G가 정확히 data distribution을 모사할 수 있다면 거기서 뽑은 sample은 완벽히 data와 구별할 수 없다.\n",
    "#### 한편 discriminator model D는 현재 자기가 보고 있는 sample이 training data에서 온 것(진짜)인지 혹은 G로부터 만들어진 것인지를 구별하여 각각의 경우에 대한 확률을 estimate한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vanilla_gan](img/vanilla_gan_1.PNG)\n",
    "D의 입장에서는 data로부터 뽑은 sample x는 D(x)=1이 되고, 임의의 noise distribution으로부터 뽑은 input z를 G에 넣고 만든 sample에 대해서는 D(G(z))=0이 되도록 노력합니다. 즉, D는 실수할 확률을 낮추기(mini) 위해 노력하고 반대로 G는 D가 실수할 확률을 높이기(max) 위해 노력하는데, 둘을 같이 놓고 보면 \"**minimax two-player game or minimax problem**\"이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adversarial Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator's distribution \\\\(p_g\\\\) over data x를 학습하기 위해 generator의 input으로 들어갈 noise variables \\\\(p_z(z)\\\\)에 대한 prior를 정의하고, data space로의 mapping을 \\\\(G(z;\\theta_g)\\\\)라 표현할 수 있습니다. 여기서 G는 미분 가능한 함수로써 \\\\(\\theta_g\\\\)를 parameter로 갖는 multilayer perceptron입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한편 Discriminator 역시 multilayer perceptron으로 \\\\(D(x;\\theta_d)\\\\)로 나타내며 output은 확률 single scaler 값이 된다. D(x)는 x가 \\\\(p_g\\\\)가 아닌 data distribution으로부터 왔을 확률을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서, 이를 수식으로 정리하면 다음과 같은 value function V(G, D)에 대한 minimax problem을 푸는 것과 같아진다.\n",
    "$ \\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}~(x)}[log D(x)] + \\mathbb{E}_{z\\sim p_x(z)}[log(1-D(G(z)))]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 극단적인 예\n",
    "이상적인 상황에서의 D입장을 살펴보면 D는 아주 잘 구별 하는 녀석이므로 D가 보는 sample x가 실제로 data distribution으로부터 온 녀석이라면 D(x)=1이므로 첫번째 term에서 log 값이 사라지고 G(z)가 만들어낸 녀석이라면 D(G(z))=0이므로 두번째 term역시 0으로 사라진다. 이 때가 D의 입장에서 V의 \"최대값\"을 얻을 수 있다는 것은 자명하다.\n",
    "\n",
    "반대로 G의 입장에서 살펴보면 G는 아주 잘 속이는 녀석이므로 D(G(z))=1이 되고 두번째 term은 $ -\\infty$가 된다. 이 때 G의 입장에서 V의 \"최소값\"을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그림을 통한 예\n",
    "![example gan](img/vanilla_gan_2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검은 점선이 data generating distribution, 파란 점선이 discriminator distribution, 녹색 선이 generative distribution이다. 밑에 x와 z선은 각각 x와 z의 domain을 나타내며 위로 뻗은 화살표가 x=G(z)의 mapping을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음 시작할 때는 (a)와 같이 $p_g$가 $p_data$와 전혀 다르게 생긴 것을 볼 수 있고 이 상태에서 discriminator가 두 distribution을 구별하기 위해 학습을 하면 (b)와 같이 좀 더 smooth하고 잘 구별하는 distribution이 만들어진다. 이후 G가 현재 discriminator가 구별하기 어려운 방향으로 학습을 하면 (c)와 같이 좀 더 $p_g$가 $p_data$와 가까워지게 되고 이런식으로 쭉 학습을 반복하다보면 결국에는 $p_g=p_data$가 되어 discriminator가 둘을 전혀 구별하지 못하는 즉, $D(x)={1\\over2}$인 상태가 된다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실용적인 TIP\n",
    "위의 value function에서 log(1-D(G(z)))부분을 G에 대해 minimize하는 대신 log(D(G(z)))를 maximize 하도록 G를 학습시킨다.\n",
    "\n",
    "G가 초기에는 아주 이상한 image들을 생성하기 때문에 D가 너무도 쉽게 이를 real image와 구별하게 되고 따라서 log(1-D(G(z)))값이 0으로 saturate하여 gradient를 계산해보면 아주 작은 값이 나오기 때문에 학습 속도가 매우 느려진다.\n",
    "\n",
    "하지만 문제를 $G=\\arg\\max_Glog(D(G(z)))$로 바꾸게 되면 초기에 D가 G로 나온 image를 잘 구별한다고 해도 값이 $-\\infty$로 가게 되어 위와 같은 문제가 생기지 않기 때문에 원래 문제와 같은 fixed point를 얻게 되면서도 stronger gradient를 줄 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 이론적 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이론적 결과 부분도 크게는 두 가지로 나뉘는데 먼저 앞서 소개한 minimax problem이 $p_g = p_{data}$에서 global optimum을 갖는다는 것을 보이고, 이어서 이 논문에서 소개하는 알고리즘이 global optimum을 찾는다는 것을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때, 지금까지 잘 사용하던 Multilayer perceptron을 사용하여 내용을 이어가는 것이 아니라 이론적 증명을 편하게 하기 위해 약간의 기믹?을 사용합니다. 저자는 non-parametric setting을 사용했다고 표현하는데, 좀 더 풀어 말하면 MLP를 사용하는 것은 결국 parameter θ를 학습하는 것이므로 직접적으로 probability density function을 학습하는 것과는 차이가 있다는 것이죠.\n",
    "\n",
    "즉, 앞으로 나올 이론적 증명 등은 model이 infinite capacity를 가지고 있으며, 수렴에 관해 애기할 때도 probability density function 공간에서 얘기한다는 것을 염두에 두면 되겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}~(x)}[log D(x)] + \\mathbb{E}_{z\\sim p_x(z)}[log(1-D(G(z)))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Global Optimality of $p_g=p_{data}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**proposition 1**\n",
    "\n",
    "For G fixed, the optimal discriminator D is\n",
    "$$ D_{G}^{*}(x) = {p_{data}(x)\\over P_{data}(x)+p_g(x)}$$\n",
    "\n",
    "Proof. The training criterion for the discriminator D, given any generator G, is to maximize the quantity V(G,D)\n",
    "$$ \\begin{align}V(G,D) &= \\int_x p_{data}~(x)log(D(x))dx + \\int_z p_z(z)log(1-D(G(z)))dz \\\\ &= \\int_x p_{data}~(x)log(D(x)) + p_g(x)log(1-D(x))dx \\end{align} $$\n",
    "For any $(a,b) \\in \\mathbb{R}^2 \\setminus \\{0,0\\}$, the function $y \\rightarrow {\\rm a} log(y) + {\\rm b} log(1-y)$ achieves its maximum in [0,1] at $\\frac{a}{a+b}$. The discriminator does not need to be defined outside of $Supp(p_{data}) \\cup Supp(p_g)$, concluding the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국  $\\min_G \\max_D V(G,D)$에서 안 쪽의 max 문제부터 풀어주면 문제가 다음과 같이 reformulate 됩니다:\n",
    "$$ \\begin{align} C(G) & = \\max_D V(G,D) \\\\ \n",
    "&= \\mathbb{E}_{x \\sim p_{data}} \\left[ log D^*_G(x) \\right] + \\mathbb{E}_{z\\sim p_z}\\left[ log(1-D^*_G(G(z))) \\right] \\\\ \n",
    "&= \\mathbb{E}_{x \\sim p_{data}} \\left[ log D^*_G(x) \\right] + \\mathbb{E}_{x\\sim p_g}\\left[ log(1-D^*_G(x)) \\right] \\\\ \n",
    "&= \\mathbb{E}_{x \\sim p_{data}} \\left[ log \\frac{p_{data}~(x)}{p_{data}~(x)+p_{g}(x)} \\right] + \\mathbb{E}_{x\\sim p_g} \\left[ log \\frac{p_{g}(x)}{p_{data}~(x)+p_{g}(x)} \\right] \\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem 1.\n",
    "The global minimum of the virtual training criterion C(G) is achieved if and only if $p_g=p_{data}$. At that point, C(G) achieves the value −log(4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proof.\n",
    "For $p_g = p_{data}$, $D_G^*(x)={1\\over2}$ 임은 자명하고 다음 수식도 자연히 따라온다.\n",
    "$$C(G) = \\mathbb{E}_{x \\sim p_{data}} \\left[ -log(2)\\right] + \\mathbb{E}_{x \\sim p_{g}} \\left[ -log(2)\\right]=-log(4).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 값이 best possible value of C(G)란 것을 알기 위해서는 다음과 같이 C(G)를 표현하는 것이 증명의 키 입니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}C(G) &= C(G) + log(4) -log(4) \\\\ &= \\mathbb{E}_{x \\sim p_{data}} \\left[ log \\frac{p_{data}~(x)}{p_{data}~(x)+p_{g}(x)} \\right] + \\mathbb{E}_{z\\sim p_x(z)} \\left[ log \\frac{p_{g}(x)}{p_{data}~(x)+p_{g}(x)} \\right] + log(2) + log(2) - log(4) \\\\ &= -log(4) + KL \\left( p_{data} || \\frac{p_{data}~+ p_g}{2}\\right) + KL \\left( p_g|| \\frac{p_{data}~+ p_g}{2}\\right) \\\\ &= -log(4) + 2\\cdot JSD(p_{data}||p_g) \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 KL은 Kullback-Leibler divergence이고 JSD는 Jensen-Shannon divergence입니다. JSD는 항상 양수이고 두 distribution이 일치할 때만 0이므로 $C^∗=−log(4)$가 C(G)의 global minimum이며 그 유일한 해가 $p_g=p_{data}$임을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고 **:\n",
    "\n",
    "**- Kullback-Leibler divergence**\n",
    "$$ D_{KL}(P||Q) = \\sum_i P(i) log\\frac{P(i)}{Q(i)}$$\n",
    "- P라는 distribution이 있을 때 (보통은 estimate한)Q가 P랑 얼마나 다른지를 측정하는 값\n",
    "\n",
    "**- Jensen-Shannon divergence**\n",
    "$$ {\\rm JSD}(P \\parallel Q)= \\frac{1}{2}D(P \\parallel M)+\\frac{1}{2}D(Q \\parallel M)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convergence of Algorithm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimax problem을 잘 풀기만 하면 (즉, global optimal을 찾으면), generator가 만드는 probability distribution($p_g$)이 data distribution($p_{data}$)과 정확히 일치하도록 할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 논문에서는 이미  신경망 모델(MLP)을 사용하여 G와 D를 정의하고 각각을 fix한 상태에서 번갈아가며 문제를 풀어주는 전략을 제시했기 때문에 이제 남은 것은 제시한 알고리즘이 문제를 잘 풀어주는가? 혹은 Global Optimum인 $p_g=p_{data}$로 수렴하는가?를 확인하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition**\n",
    "\n",
    "If G and D have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given G, and $p_g$ is updated so as to improve the criterion\n",
    "$$ \\mathbb{E}_{x \\sim p_{data}} \\left[ log D^*_G(x) \\right] + \\mathbb{E}_{x\\sim p_g}\\left[ log(1-D^*_G(x)) \\right] $$\n",
    "then $p_g$ converges to $p_{data}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">** Proof.**  Consider $V(G,D)=U(p_g,D)$ as a function of $p_g$ as done in the above criterion. Note that $U(p_g,D)$ is convex in $p_g$. The subderivatives of a supremum of convex functions include the derivative of the function at the point where the maximum is attained. This is equivalent to computing a gradient descent update for pg at the optimal D given the corresponding G. $sup_DU(p_g,D)$ is convex in $p_g$ with a unique global optima as proven in Thm 1, therefore with sufficiently small updates of $p_g$, $p_g$ converges to $p_x$, concluding the proof.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In practice, adversarial nets represent a limited family of $p_g$ distributions via the function $G(z;θ_g)$, and we optimize $θ_g$ rather than $p_g$ itself.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([784, 128]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([128, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "\n",
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([100, 128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([128, 784]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "\n",
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real, D_logit_real = discriminator(X)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)\n",
    "\n",
    "D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(1. - D_fake))\n",
    "G_loss = -tf.reduce_mean(tf.log(D_fake))\n",
    "\n",
    "# Alternative losses:\n",
    "# -------------------\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "#D_loss = D_loss_real + D_loss_fake\n",
    "#G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "\n",
    "mb_size = 128\n",
    "Z_dim = 100\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py:943: UserWarning: Warning: converting a masked element to nan.\n",
      "  vmin = float(vmin)\n",
      "c:\\program files\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py:944: UserWarning: Warning: converting a masked element to nan.\n",
      "  vmax = float(vmax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 1.386\n",
      "G_loss: 0.6931\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-278ca608e69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_loss_curr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD_solver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_loss_curr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mG_solver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mc:\\program files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for it in range(10000):\n",
    "    if it % 1000 == 0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "    X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img000](out/000.png)\n",
    "![img001](out/001.png)\n",
    "![img002](out/002.png)\n",
    "![img003](out/003.png)\n",
    "![img004](out/004.png)\n",
    "![img005](out/005.png)\n",
    "![img006](out/006.png)\n",
    "![img007](out/007.png)\n",
    "![img008](out/008.png)\n",
    "![img009](out/009.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
